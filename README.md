# Sign-Language-Translator
Communication among deaf-mute people and normal people is more
difficult because normal people cannot perceive the speculation and
feeling of deaf-mute people.
So to ease this problem, we are going to develop an application with help
of ML that converts sign language. This application will be based on an
ML model that can recognize the different sign language gestures for
accurate translation. 

There are different sign languages practiced in different countries. For example,
India uses Indian Sign Language (ISL) while the USA uses American sign
language (ASL). So, you first need to decide which type you wish to implement.
After gathering the datasets, prepare the ML model for training. There are many
options for this such as TensorFlow, Kera's, PyTorch, Google’s Teachable
Machine etc. For this project, I am using Google’s Teachable Machine, which is
an online ML model creator service. Now, feed the datasets into your choice of
ML model creator and capture the pictures of different hand gestures/signs
with a camera. Remember to label them as per their meaning.

The Proposed System Gives Two Way Communication System, first
with Normal people to Deaf and Dumb people, Second with Deaf and
Dumb people to Normal people. For implementation of this system we
give audio as input so that audio matching using pattern matching
techniques are used. The signs for corresponding audio matched will
be displayed as output. Second, we require web camera is required for
capturing the Sign gestures. Sign language gesture is recognized and
showed the output in audio forms
